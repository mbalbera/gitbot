🛠️ System Prompt Writing Guide (for Building Reliable LLM Agents)
System prompts are like blueprints for your assistant. They define what the agent is, what it should do, and how it should behave across edge cases and ambiguity. Use this guide to write long, effective system prompts that scale across complex tasks.

🔧 1. Define the Assistant’s Role
Start with a clear, specific identity.

✅ Do:

You are a skilled assistant that translates natural language into structured outputs with high accuracy.

❌ Don’t:

You are a helpful AI.

Clarity here sets the tone for every other rule.

🧱 2. Establish Context
Use a “## CONTEXT” section to describe the world the assistant operates in.

Typical elements include:

Resources available (e.g., metadata, prior messages, tools)

Interfaces (e.g., {user_input}, {date}, {user_information})

Constraints on what the assistant can or cannot assume

Rules around memory or history

🎯 3. Define Goals and Preferred Behavior
Use a “## GOALS” section to define the assistant’s priorities.

If there is one large goal break problem into:
- Primary Objective: What’s the main job?
- Preferred Behavior: How should it act when confident vs. uncertain?
- Fallback Handling: When should it ask follow-up questions vs. guess?
- This section shapes decision-making under uncertainty.

If there are sequential steps or processes:
1. Step one do ABC
2. Then do DEF
3. So on and so forthyea 

⏱️ 4. Address Time, History, and Follow-ups
Many prompts are vague (“this year,” “last time,” “same as before”).

Build rules for:

Time references (e.g., assume current year if not provided)

History (e.g., only use if context is clearly a follow-up)

Fallbacks (e.g., ask follow-up if more than 2 interpretations exist)

🗣️ 5. Specify Tone
Define the communication style.

Good defaults:

Clear and direct

Friendly, but not overly casual

Confident and helpful, not robotic

Example:

```md
Use a tone that feels like a sharp, reliable coworker—not a formal assistant.
```
📈 6. Plan for Scalability
System prompts should generalize to new inputs, structures, or tasks.

Tips:

Avoid hardcoding names or structures unless required.

Point the assistant to dynamic sources like metadata, examples, or context variables.

🔀 7. Multi-Step Behavior
If tasks require multiple outputs (e.g., steps, queries, suggestions), define:

How many steps to return before asking for clarification

Whether to group related outputs

Whether to summarize or explain assumptions

Keep it efficient—encourage the assistant to avoid over-generating.

🧾 8. Output Format
Be specific about formatting expectations.

Common patterns:

Use markdown code blocks

Explain assumptions briefly above outputs

Return errors or clarifying questions in plain language

✅ 9. Final Instruction
Reinforce expected behavior in one line.

Example:

```md
Use the user input and available context to generate your best answer. Only ask questions if you're truly blocked.
```
📌 Prompt Template Summary
```md
You are a [expert assistant description].
```

## CONTEXT  
[Resources, constraints, interfaces, history rules]

## GOALS  
1. Primary Objective  
2. Preferred Behavior  
3. Ambiguity Handling  
4. History/Time Use

## TONE  
[Voice, style expectations]

## SCALABILITY  
[How to generalize and avoid overfitting to known data]

## OUTPUT FORMAT  
[Explanation and output expectations]

FINAL INSTRUCTION  
[One-sentence directive]
